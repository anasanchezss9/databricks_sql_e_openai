model_run_id = model_details.run_id
r2 = mlflow.get_run(model_run_id).data.metrics['r2']

try:
    #Compare the challenger r2 score to the existing champion if it exists
    champion_model = client.get_model_version_by_alias(model_name, "Champion")
    champion_r2 = mlflow.get_run(champion_model.run_id).data.metrics['r2']
    print(f'Champion r2 score: {champion_r2}. Challenger r2 score: {r2_score}.')
    metric_r2_passed = r2_score >= champion_r2
except:
    print(f"No Champion found. Accept the model as it's the first one.")
    metric_r2_passed = True

print(f'Model {model_name} version {model_details.version} metric_r2_passed: {metric_r2_passed}')
# Tag that r2 metric check has passed
client.set_model_version_tag(name=model_name, version=model_details.version, key="metric_r2_passed", value=metric_r2_passed)